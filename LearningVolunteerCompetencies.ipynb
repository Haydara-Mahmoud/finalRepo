{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from ipywidgets import *\n",
    "from IPython.display import clear_output, display, Javascript\n",
    "from tkinter import Tk, filedialog\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import plotly.express as px\n",
    "import random\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skmultilearn.adapt import BRkNNaClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loginLogout():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out11 = widgets.Output()\n",
    "\n",
    "def on_select_Column_Change(event):\n",
    "    if (columnNullList.value !=0):\n",
    "        dic = getNullDict()\n",
    "        key_list = list(dic.keys())\n",
    "        value_list = list(dic.values())\n",
    "        position = value_list.index(columnNullList.value)\n",
    "        s = key_list[position]\n",
    "        getNullValuesfor(getGeneralDataset(),s)\n",
    "    else:\n",
    "        out11.clear_output()\n",
    "\n",
    "columnNullList = Dropdown(\n",
    "            options={'',0},\n",
    "            value=0,\n",
    "            description='Choose attribute:',\n",
    "            style= {'description_width':'auto'}\n",
    "            )\n",
    "columnNullList.observe(on_select_Column_Change, names=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "# 1 - Showing file chooser dialog -> Returns file selected\n",
    "def select_files(b):\n",
    "    #clear_output()                                        # Button is deleted after it is clicked.\n",
    "    root = Tk()\n",
    "    root.withdraw()                                        # Hide the main window.\n",
    "    root.call('wm', 'attributes', '.', '-topmost', True)   # Raise the root to the top of all windows.\n",
    "    b.files = filedialog.askopenfilename(multiple=False)   # List of selected files will be set button's file attribute.\n",
    "    return b.files                                         # Print the list of files selected.\n",
    "# -------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2 - Read dataset -> This function is so specific for \"PersonTasks\" dataset -> Returns dataset\n",
    "def read_file(file_path):\n",
    "    # Reading dataset:\n",
    "    if withConsole==True:\n",
    "        outputText.append('>> Reading dataset file : '+str(file_path))\n",
    "    dataset = pd.read_json(file_path,orient=\"columns\");\n",
    "    if checkIfPersonTasksDataset(dataset) == True:\n",
    "        # Flattening dataset\n",
    "        if withConsole==True:\n",
    "            outputText.append('>> Flattening dataset file : '+str(file_path))\n",
    "        dataset = showJSONDataset(file_path)\n",
    "        # Check how many people in the dataset\n",
    "        numberOfPersons = dataset.personID.unique();\n",
    "        if withConsole==True:\n",
    "            outputText.append('>> Found '+str(len(numberOfPersons))+\" volunteer(s) in dataset\")\n",
    "        # Takes the first person\n",
    "        selectedPersonID = numberOfPersons[0]\n",
    "        if withConsole==True:\n",
    "            if (len(numberOfPersons)>1):\n",
    "                outputText.append('>> Filtering dataset to one volunteer which personID = '+str(selectedPersonID))\n",
    "        # Filter dataset\n",
    "        dataset = dataset[dataset.personID==selectedPersonID]\n",
    "        # Replacing personID by 1 and adding personName with a random number from namesList list\n",
    "        # dataset = dataset.drop([\"personID\"],axis=1)\n",
    "        dataset.personID = dataset.personID.replace(selectedPersonID,1)\n",
    "        outputText.append('>> Changing personID from '+str(selectedPersonID)+' to 1')\n",
    "        namesList = ['Jack','Jordan','Axel','Ian','Luis','Nicolas',\n",
    "            'Sophia','Charlotte','Scarlett','Ivy','Lucy','Ariana']\n",
    "        name = random.choice(namesList)\n",
    "        dataset['personName'] = name\n",
    "        if withConsole==True:\n",
    "            outputText.append('>> Adding personName attribute with name : '+str(name))\n",
    "        # Visualizing personID, taskType1, taskType2 and taskDuration\n",
    "        if withConsole==True:\n",
    "            outputText.append('>> Making a Sunburst Visualization for taskType1, taskType2 and taskDuration for : '+str(name))\n",
    "        datasetVisualization = dataset[['personName','taskType1','taskType2','taskDuration']]\n",
    "        fig = px.sunburst(datasetVisualization, path=[datasetVisualization[\"personName\"].tolist(),\n",
    "                                                      datasetVisualization[\"taskType1\"].tolist(), \n",
    "                                                      datasetVisualization[\"taskType2\"].tolist()], \n",
    "                          values=datasetVisualization[\"taskDuration\"].tolist())\n",
    "        fig.update_layout(showlegend=True,\n",
    "                          title_text=\"Sunburst chart for: \"+ name)\n",
    "        # Statistics for all attributes\n",
    "        if withConsole==True:\n",
    "            outputText.append('>> Making some statistics for: '+str(name))\n",
    "        datasetNumericStatistics = dataset.describe()\n",
    "        datasetStatistics = dataset.describe(include='all')\n",
    "        \n",
    "        # Getting all Null/NaN columns which null/nan values != 0 and show them in columnNullList drop down list\n",
    "        allNaNNullValues = showNullNaNValues(dataset)\n",
    "        dropDownValue = 1;\n",
    "        allNaNNullValuesNotZero = allNaNNullValues[allNaNNullValues[\"# of null/nan values\"]!=0].reset_index(drop=True)\n",
    "        global nullDict\n",
    "        nullDict = {'':0}\n",
    "        for i in range(len(allNaNNullValuesNotZero)):\n",
    "            nullDict[str(allNaNNullValuesNotZero[\"Columns\"][i])] = dropDownValue;\n",
    "            dropDownValue = dropDownValue + 1\n",
    "        columnNullList.options = nullDict\n",
    "        columnNullList.value = 0\n",
    "        \n",
    "        with output:\n",
    "            out1 = widgets.Output()\n",
    "            out2 = widgets.Output()\n",
    "            out3 = widgets.Output()\n",
    "            out4 = widgets.Output()\n",
    "            out5 = widgets.Output()\n",
    "            out7 = widgets.Output()\n",
    "            out10 = widgets.Output()\n",
    "            if withConsole==True:\n",
    "                out6 = widgets.Output()\n",
    "                finalResult = Accordion(children=[out6,out1,out2,out3], selected_index=None)\n",
    "                finalResult.set_title(0,\"Console:\")\n",
    "                finalResult.set_title(1,\"Dataset View:\")\n",
    "                finalResult.set_title(2,\"Visulaization:\")\n",
    "                finalResult.set_title(3,\"Statistics:\")\n",
    "                # Tab inside Statistics accordion\n",
    "                tabChildren = [out4,out5,out7,out10]\n",
    "                tab = Tab(children=tabChildren)\n",
    "                tab.set_title(0,'Numeric data:')\n",
    "                tab.set_title(1,'All data:')\n",
    "                tab.set_title(2,'Null/NaN values:')\n",
    "                tab.set_title(3,'Null/NaN rows:')\n",
    "                \n",
    "                consoleText = Textarea(value=\"Console:\", rows=10, disabled=True, layout=Layout(width=\"auto\"))\n",
    "                for text in outputText:\n",
    "                    consoleText.value = consoleText.value + \"\\r\" + text\n",
    "            else:\n",
    "                finalResult = Accordion(children=[out1,out2,out3], selected_index=None)\n",
    "                finalResult.set_title(0,\"Dataset View:\")\n",
    "                finalResult.set_title(1,\"Visulaization:\")\n",
    "                finalResult.set_title(2,\"Statistics:\")\n",
    "                # Tab inside Statistics accordion\n",
    "                tabChildren = [out4,out5,out7,out10]\n",
    "                tab = widgets.Tab(children=tabChildren)\n",
    "                tab.set_title(0,'Numeric data:')\n",
    "                tab.set_title(1,'All data:')\n",
    "                tab.set_title(2,'Null/NaN values:')\n",
    "                tab.set_title(3,'Null/NaN rows:')\n",
    "                \n",
    "            display(finalResult)\n",
    "            with out1:\n",
    "                display(dataset)\n",
    "            with out2:\n",
    "                display(fig)\n",
    "            with out3:\n",
    "                display(tab)\n",
    "            with out4:\n",
    "                display(datasetNumericStatistics)\n",
    "            with out5:\n",
    "                display(datasetStatistics)\n",
    "            with out7:\n",
    "                display(allNaNNullValues)\n",
    "            with out10:\n",
    "                # out11 is global\n",
    "                display(VBox([columnNullList,out11]))\n",
    "            if withConsole==True:\n",
    "                with out6:\n",
    "                    display(consoleText)\n",
    "            '''\n",
    "            display(title1)\n",
    "            display(dataset)\n",
    "            display(title2)\n",
    "            display(fig)\n",
    "            display(title3)\n",
    "            display(datasetStatistics)\n",
    "            '''\n",
    "        enableDisableButton(preprocessingButton,1)\n",
    "        return dataset\n",
    "    else:\n",
    "        errorMessage = getMessage('error','You select a wrong dataset! Please select a suitable one!')\n",
    "        enableDisableButton(preprocessingButton,0)\n",
    "        with output:\n",
    "            display(errorMessage)\n",
    "        return False\n",
    "\n",
    "def getNullDict():\n",
    "    return nullDict\n",
    "    \n",
    "def getNullValuesfor(dataset,columnName):\n",
    "    out11.clear_output()\n",
    "    nullValues = dataset[dataset[columnName].isna()]\n",
    "    with out11:\n",
    "        display(nullValues)    \n",
    "# -------------------------------------------------------------------------------------------------------------------------\n",
    "# 3 - After reading a dataset -> ordering events\n",
    "def order_events(b):\n",
    "    fileselect1.icon = \"spinner\"\n",
    "    global outputText;\n",
    "    outputText = [];\n",
    "    # Checking if we want it with console or not\n",
    "    global withConsole\n",
    "    withConsole = False\n",
    "    file = select_files(b)\n",
    "    if '.json' in file:\n",
    "        output.clear_output()\n",
    "        # defining global variable in order accessing it in the next cells.\n",
    "        global finalDataset\n",
    "        finalDataset = read_file(file)\n",
    "        fileselect1.icon = \"file\"\n",
    "        return finalDataset\n",
    "    else:\n",
    "        output.clear_output()\n",
    "        fileselect1.icon = \"file\"\n",
    "        with output:\n",
    "            informationMessage = getMessage('information','You have to choose a dataset with a JSON format!!')\n",
    "            enableDisableButton(preprocessingButton,0)\n",
    "            display(informationMessage)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------            \n",
    "def order_eventsWithOutput(b):\n",
    "    fileselect2.icon = \"spinner\"\n",
    "    global outputText;\n",
    "    outputText = [];\n",
    "    # Checking if we want it with console or not\n",
    "    global withConsole\n",
    "    withConsole = True\n",
    "    file = select_files(b)\n",
    "    if '.json' in file:\n",
    "        output.clear_output()\n",
    "        # defining global variable in order accessing it in the next cells.\n",
    "        global finalDataset\n",
    "        finalDataset = read_file(file)\n",
    "        fileselect2.icon = \"info-circle\"\n",
    "        return finalDataset\n",
    "    else:\n",
    "        fileselect2.icon = \"info-circle\"\n",
    "        output.clear_output()\n",
    "        with output:\n",
    "            informationMessage = getMessage('information','You have to choose a dataset with a JSON format!!')\n",
    "            enableDisableButton(preprocessingButton,0)\n",
    "            display(informationMessage)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "# 4 - Check if this is the target dataset \"PersonTasks\" dataset\n",
    "def checkIfPersonTasksDataset(dataset):\n",
    "    columns = dataset.columns\n",
    "    if len(columns) == 13:\n",
    "        if ('taskType1' in columns) & ('taskType2' in columns) & ('taskDuration' in columns):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "# 5 - Messages\n",
    "def getMessage(messsageType,messageText):\n",
    "    finalMessage = ''\n",
    "    if messsageType == 'error':\n",
    "        finalMessage = Button(description=str(messageText),icon=\"remove\",layout=Layout(width='auto'),button_style=\"danger\",disabled=True)\n",
    "        # widgets.HTML(value='<img style=\"float: left\" src=\"./icons/error.png\" width=\"30px\" height=\"30px\"/>&nbsp<h4 style=\"color:red;\">Error: <h4>&nbsp <span>'+  +'</span>')\n",
    "    else:\n",
    "        finalMessage = Button(description=str(messageText),icon=\"info-circle\",layout=Layout(width='auto'),button_style=\"info\",disabled=True)\n",
    "        # widgets.HTML(value='<img style=\"float: left\" src=\"./icons/information.png\" width=\"30px\" height=\"30px\"/>&nbsp<h4 style=\"color:blue;\">Information: <h4>&nbsp <span>'+ str(messageText) +'</span>')\n",
    "    return finalMessage\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "# 6 - These three functions to flatten dataset if it has nested JSON code:\n",
    "# Knowing nested JSON columns in dataset\n",
    "def extractNestedColumns(dataframe):\n",
    "    nestedColumns = [];\n",
    "    col = dataframe.columns;\n",
    "    for column in col:\n",
    "        value = dataframe[column][0];\n",
    "        if \"{\" in str(value):\n",
    "              nestedColumns.append(column);\n",
    "    return nestedColumns\n",
    "\n",
    "def splittingNestedColumns(dataframe):\n",
    "    # Taking nested json columns in dataframe\n",
    "    nestedColumns = extractNestedColumns(dataframe);\n",
    "    if len(nestedColumns)!=0:\n",
    "        for i in nestedColumns:\n",
    "            # taking every column in nestedColumns attributes and adding it to the original dataframe\n",
    "            p = pd.DataFrame(dataframe[i]);\n",
    "            f = [];\n",
    "            for j in p[i]:\n",
    "                f.append(j);\n",
    "            s = pd.DataFrame(f);\n",
    "            scol = s.columns;\n",
    "            for k in scol:\n",
    "                s = s.rename(columns={k:\"{}{}{}\".format(i,\"_\",k)})\n",
    "            scol = s.columns;\n",
    "            for n in scol:\n",
    "                dataframe[n] = s[n];\n",
    "            for j in scol:\n",
    "                dataframe[j] = s[j];\n",
    "            newDataFrame = dataframe.drop(nestedColumns,axis=1) \n",
    "    return newDataFrame\n",
    "\n",
    "# A function to show [flattened] dataset\n",
    "def showJSONDataset(datasetPath):\n",
    "    # Reading the JSON File and put it in a variable\n",
    "    datasetVariable = pd.read_json(datasetPath,orient='columns')\n",
    "    datasetVariable = splittingNestedColumns(datasetVariable)\n",
    "    return datasetVariable\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------\n",
    "# 7 - Function to enable/disable a button 0-> disable , 1->enable\n",
    "def enableDisableButton(buttonName,value):\n",
    "    if value == 0:\n",
    "        buttonName.layout = Layout(width=\"0\",height=\"0\")\n",
    "        output2.clear_output()\n",
    "        buttonName.disabled=False\n",
    "        '''\n",
    "        buttonName.button_style=\"danger\"\n",
    "        buttonName.disabled=True\n",
    "        '''\n",
    "    else:\n",
    "        buttonName.layout = Layout(width=\"auto\",height=\"auto\")\n",
    "        output2.clear_output()\n",
    "        buttonName.disabled=False\n",
    "        '''\n",
    "        buttonName.button_style=\"success\"\n",
    "        buttonName.disabled=False\n",
    "        '''\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "# 8 - Function to show categorical/numeric attributes with null/nan values\n",
    "def showNullNaNValues(dataset):\n",
    "    dataset.convert_dtypes().dtypes;\n",
    "    col = dataset.columns;\n",
    "    nullValues = list(dataset.isnull().sum());\n",
    "    colType = [];\n",
    "    for i in col:\n",
    "        if (dataset[i].dtype == \"O\") | (dataset[i].dtype == \"bool\"):\n",
    "            colType.append(\"Categorical\");\n",
    "        else:\n",
    "            colType.append(\"Numeric\");\n",
    "\n",
    "    # Making dataframe\n",
    "    columnsDict={\"Columns\":list(col),\"Types\":list(colType),\"# of null/nan values\":nullValues};\n",
    "    df = pd.DataFrame(columnsDict);\n",
    "    return df\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "# 9 - Function to get general dataset\n",
    "def getGeneralDataset():\n",
    "    return finalDataset.copy();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\"><center>Learning Volunteer Competencies</center></font>\n",
    "***\n",
    "## <img style=\"float: left\" src=\"./icons/mode.png\" width=\"25px\" height=\"25px\"/>&nbsp; Assessment Mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5674e0233e4e15bbbe10a76177efe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Assessment Mode : ', options={'Learning Method': 1}, style=DescriptionStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assessmentMode = Dropdown(\n",
    "            options={'Learning Method': 1},\n",
    "            value=1,\n",
    "            description='Assessment Mode : ',\n",
    "            style= {'description_width':'auto'}\n",
    "            )\n",
    "\n",
    "display(assessmentMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## <img style=\"float: left\" src=\"./icons/dataset.png\" width=\"25px\" height=\"25px\"/>&nbsp; Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fe73465ec04c26958f172dbb992487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Select Dataset', icon='file', layout=Layout(width='auto'), style=ButtonStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dbc87c128441fea3927088af7dcdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For printing widgets\n",
    "output = widgets.Output()\n",
    "\n",
    "# Buttons\n",
    "layout = widgets.Layout(width='auto')\n",
    "fileselect1 = Button(description=\"Select Dataset\", icon=\"file\", layout=layout, tooltip=\"Select dataset and show the result\")\n",
    "fileselect1.on_click(order_events)\n",
    "\n",
    "fileselect2 = Button(description=\"Select Dataset with console\",\n",
    "                     icon=\"info-circle\", layout=layout, tooltip=\"Select dataset and show the result step by step\")\n",
    "fileselect2.on_click(order_eventsWithOutput)\n",
    "\n",
    "buttons = HBox([fileselect1,fileselect2])\n",
    "\n",
    "\n",
    "display(buttons)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <img style=\"float: left\" src=\"./icons/pre-processing.png\" width=\"25px\" height=\"25px\"/>&nbsp; Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for preprocessing\n",
    "def extractingDateTimeFeatures(dataset,column1,column2):\n",
    "    dataset[column1] = pd.to_datetime(dataset[column1])\n",
    "    dataset[column2] = pd.to_datetime(dataset[column2])\n",
    "\n",
    "    # Extracting date and time\n",
    "    dateFrom = [d.date() for d in dataset[column1]]\n",
    "    dateTo = [d.date() for d in dataset[column2]]\n",
    "    timeFrom = [d.time() for d in dataset[column1]]\n",
    "    timeTo = [d.time() for d in dataset[column2]]\n",
    "\n",
    "    # Insert them in dataset in specific locations\n",
    "    dataset.insert(7,\"dateFrom\",dateFrom)\n",
    "    dataset.insert(8,\"dateTo\",dateTo)\n",
    "    dataset.insert(9,\"timeFrom\",timeFrom)\n",
    "    dataset.insert(10,\"timeTo\",timeTo)\n",
    "    \n",
    "    # Return dataset\n",
    "    return dataset\n",
    "\n",
    "def deleteAttributes(dataset,listOfAttributes):\n",
    "    dataset = dataset.drop(listOfAttributes,axis=1)\n",
    "    return dataset\n",
    "\n",
    "def getTaskDuration(t1,t2):\n",
    "    duration = t2-t1\n",
    "    duration_in_s = duration.total_seconds()\n",
    "    duration_in_h = divmod(duration_in_s, 3600)\n",
    "    duration_in_m = round(duration_in_h[1] / 3600,2)\n",
    "    finalDuration = duration_in_h[0] + duration_in_m\n",
    "    return finalDuration\n",
    "\n",
    "# This function is specific for PersonTasks dataset\n",
    "def handlingTaskDuration(dataset):\n",
    "    numberOfRows = len(dataset);\n",
    "    numberOfAffectedRows = 0;\n",
    "    for i in range(numberOfRows):\n",
    "        taskD = dataset.taskDuration[i];\n",
    "        if (pd.isna(taskD)):\n",
    "            t1 = pd.to_datetime(dataset.taskDateFrom[i]);\n",
    "            t2 = pd.to_datetime(dataset.taskDateTo[i]);\n",
    "            taskDuration = getTaskDuration(t1,t2)\n",
    "            dataset.loc[i, \"taskDuration\"] = taskDuration;\n",
    "            numberOfAffectedRows = numberOfAffectedRows + 1;\n",
    "    return dataset, numberOfAffectedRows\n",
    "\n",
    "# A function to return number of tasks that are accomplished between two specific hours\n",
    "# Parameters hour1, hour2 from string datatype\n",
    "def getNumberOfTasksBetweenTwoHours(dataset,column,personID,hour1,hour2):\n",
    "    resultedRows = dataset[dataset.personID==personID];\n",
    "    \n",
    "    list1=[]; # A list of all hours between the two defined hours\n",
    "    hoursRange = pd.date_range(hour1,hour2,freq=\"1min\")\n",
    "    for data in hoursRange:\n",
    "        list1.append(data.time())\n",
    "\n",
    "    filteredColumn = resultedRows[column];\n",
    "    list2 = []; # list of all values in column which its value is in list1\n",
    "    for i in filteredColumn:\n",
    "        if (i in list1):\n",
    "            list2.append(i)\n",
    "            \n",
    "    return len(list2)\n",
    "\n",
    "def getGeneratedDataset(dataset):\n",
    "    # Column of generated dataset\n",
    "    personName = [];\n",
    "    NumberOfAccomplishedTasks = [];\n",
    "    OrganizationManagementProportion = [];\n",
    "    TrainingLearningProportion = [];\n",
    "    CoorporationProportion = [];\n",
    "    VarietyWorkProportion = [];\n",
    "    StartWorkingMorning = [];\n",
    "    WorkingLongTime = [];\n",
    "    taskLocation = [];\n",
    "    \n",
    "    numberOfVolunteers = list(dataset.personID.unique());\n",
    "    \n",
    "    for pId in numberOfVolunteers:\n",
    "        # Taking tasks for each volunteer\n",
    "        volunteerTasks = dataset[dataset.personID==pId]\n",
    "\n",
    "        # Begin extracting new attributes\n",
    "        # 1 - personName\n",
    "        volunteerName = volunteerTasks.personName.unique()\n",
    "        personName.append(volunteerName[0]);\n",
    "\n",
    "        # 2- Knowing the number of tasks:\n",
    "        totalNumberOfTasks = len(volunteerTasks.taskType1);\n",
    "        NumberOfAccomplishedTasks.append(totalNumberOfTasks)\n",
    "\n",
    "        # 3 - OrganizationManagementProportion -> Number of tasks that from\n",
    "        # taskType1='Organisation | Verwaltung', 'Bewerb | Leistungsprüfung (inkl. Vorbereitung)' and 'Einsatz'\n",
    "        # Number between 0-1.\n",
    "        OrganizationManagementProportion.append((round(len(volunteerTasks[((volunteerTasks.taskType1=='Organisation | Verwaltung') |\n",
    "                                                         (volunteerTasks.taskType1=='Einsatz'))]) / totalNumberOfTasks,2)))\n",
    "\n",
    "        # 4 - TrainingLearningProportion -> Number of tasks that from \n",
    "        # taskType1='Schulung', 'Übung' and 'Kurs | Weiterbildung'\n",
    "        # Number between 0-1.\n",
    "        TrainingLearningProportion.append((round(len(volunteerTasks[((volunteerTasks.taskType1=='Schulung') |\n",
    "                                                         (volunteerTasks.taskType1=='Übung') |\n",
    "                                                         (volunteerTasks.taskType1=='Kurs | Weiterbildung'))]) / totalNumberOfTasks,2)))\n",
    "\n",
    "        # 5 - CoorporationProportion -> Number of tasks that from\n",
    "        # taskType1='Jugend'\n",
    "        # Number between 0-1.\n",
    "        CoorporationProportion.append(round(len(volunteerTasks[(volunteerTasks.taskType1=='Jugend')])/ totalNumberOfTasks,2))\n",
    "\n",
    "        # 6 - VarietyWorkProportion -> Number of tasks that from \n",
    "        # taskType1='Sonstiges'\n",
    "        # Number between 0-1.\n",
    "        VarietyWorkProportion.append(round(len(volunteerTasks[(volunteerTasks.taskType1=='Sonstiges')|\n",
    "                                                         (volunteerTasks.taskType1=='Bewerb | Leistungsprüfung (inkl. Vorbereitung)') |\n",
    "                                                             (volunteerTasks.taskType1=='Arbeiten in der FW')])/ totalNumberOfTasks,2))\n",
    "\n",
    "        # 7 - StartWorkingMorning -> Number of tasks that from \n",
    "        # timeFrom and using getNumberOfTasksBetweenTwoHours function \"08:00:00\" and \"12:00:00\"\n",
    "        # Number between 0-1.\n",
    "        StartWorkingMorning.append(round(getNumberOfTasksBetweenTwoHours(volunteerTasks,'timeFrom',pId,'08:00:00','12:00:00')/totalNumberOfTasks,2))\n",
    "\n",
    "        # 8 - WorkingLongTime -> Number of tasks in which \n",
    "        # Taking the mean of all volunteer's taskDuration and compare each task to it and take all them that >= mean \n",
    "        # Number between 0-1 and Expresses about telorate work prassure.\n",
    "        taskDurationMean = volunteerTasks.taskDuration.mean();\n",
    "        WorkingLongTime.append(round(len(volunteerTasks[volunteerTasks.taskDuration >= taskDurationMean])/totalNumberOfTasks,2))\n",
    "\n",
    "        # 9 - taskLocation -> Number of unique locations\n",
    "        # Number between 0-1.\n",
    "        # -> Mobility.\n",
    "        taskLocation.append(round(len(volunteerTasks.taskLocation.unique())/totalNumberOfTasks,2))\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # -------------------------------------------GETTING DICTIONARY--------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    generatedDatasetDict = {\n",
    "        'personName':personName,\n",
    "        'NumberOfAccomplishedTasks':NumberOfAccomplishedTasks,\n",
    "        'OrganizationManagementProportion':OrganizationManagementProportion,\n",
    "        'TrainingLearningProportion':TrainingLearningProportion,\n",
    "        'CoorporationProportion':CoorporationProportion,\n",
    "        'VarietyWorkProportion': VarietyWorkProportion,\n",
    "        'StartWorkingMorning': StartWorkingMorning,\n",
    "        'WorkingLongTime': WorkingLongTime,\n",
    "        'taskLocation':taskLocation\n",
    "    }\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    # -------------------------------------------GETTING DATAFRAME---------------------------------------------\n",
    "    # ---------------------------------------------------------------------------------------------------------\n",
    "    generatedDatasetDataFrame = pd.DataFrame(generatedDatasetDict)\n",
    "    return generatedDatasetDataFrame\n",
    "\n",
    "def getFinalPreprocessedDataset():\n",
    "    return finalPreprocessedDataset.copy()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# activating prediction button\n",
    "def activatePredictionButton():\n",
    "    if (runModelButton.disabled==False) & (preprocessingButton.disabled==True):\n",
    "        predictionButton.disabled=False\n",
    "    else:\n",
    "        predictionButton.disabled=True\n",
    "\n",
    "def preprocessingOnClickEvent(event):\n",
    "    preprocessedDataset = getGeneralDataset()\n",
    "    preprocessingOutput = [];\n",
    "    preprocessingOutput.append(\">> Extracting time and date from taskDateFrom and taskDateTo attributes.\")\n",
    "    preprocessedDataset = extractingDateTimeFeatures(preprocessedDataset,'taskDateFrom','taskDateTo')\n",
    "    listOfDeletedAttributes = ['taskName', 'iVolunteerSource', 'iVolunteerUUID', 'taskGeoInformation_latitude', 'taskGeoInformation_longitude','taskGeoInformation_gridID']\n",
    "    preprocessedDataset = deleteAttributes(preprocessedDataset,listOfDeletedAttributes)\n",
    "    preprocessingOutput.append(\">> Deleting unnecessary \"+str(len(listOfDeletedAttributes))+\" attributes:\")\n",
    "    for attribute in listOfDeletedAttributes:\n",
    "        preprocessingOutput.append(\">> Deleting \"+str(attribute)+\".\")\n",
    "    nullValuesList = showNullNaNValues(preprocessedDataset)\n",
    "    nullValuesList = nullValuesList[nullValuesList[\"# of null/nan values\"] != 0].reset_index(drop=True)\n",
    "    for i in range(len(nullValuesList)):\n",
    "        if (nullValuesList[\"# of null/nan values\"][i] > 1):\n",
    "            preprocessingOutput.append('>> Found '+str(nullValuesList[\"# of null/nan values\"][i])+' Null/NaN values in '+str(nullValuesList['Columns'][i])+' attribute')\n",
    "        else:\n",
    "            preprocessingOutput.append('>> Found '+str(nullValuesList[\"# of null/nan values\"][i])+' Null/NaN value in '+str(nullValuesList['Columns'][i])+' attribute')\n",
    "    preprocessingOutput.append('>> Handling Null/NaN values.')\n",
    "    preprocessedDataset, numberOfAffectedRows = handlingTaskDuration(preprocessedDataset)\n",
    "    preprocessingOutput.append('>> '+str(numberOfAffectedRows)+' rows has affected and handled!!')\n",
    "    preprocessingOutput.append('>> Making dataset fit the learning model......')\n",
    "    global finalPreprocessedDataset\n",
    "    finalPreprocessedDataset = getGeneratedDataset(preprocessedDataset)\n",
    "    with output2:\n",
    "        out9 = widgets.Output()\n",
    "        out12 = widgets.Output()\n",
    "        preporcessingResult = Accordion(children=[out9,out12], selected_index=None)\n",
    "        preporcessingResult.set_title(0,\"Console for pre-processing step:\")\n",
    "        preporcessingResult.set_title(1,\"Pre-processed Dataset:\")\n",
    "        preprocessingConsoleText = Textarea(value=\"Preprocessing Console:\", rows=10, disabled=True, layout=Layout(width=\"auto\"))\n",
    "        for text in preprocessingOutput:\n",
    "            preprocessingConsoleText.value = preprocessingConsoleText.value + \"\\r\" + text\n",
    "        display(preporcessingResult)\n",
    "        with out9:\n",
    "            display(preprocessingConsoleText)\n",
    "        with out12:\n",
    "            display(finalPreprocessedDataset)\n",
    "    preprocessingButton.disabled = True\n",
    "    activatePredictionButton()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389e9ff9bbe4433b9162e6255532dd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Make preprocessing', icon='gears', layout=Layout(height='0', width='0'), style=ButtonStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad51a22f9584b08b3484358b516fb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output2 = widgets.Output()\n",
    "preprocessingButton = Button(description=\"Make preprocessing\", layout=Layout(width=\"0\", height=\"0\"), icon='gears')\n",
    "preprocessingButton.on_click(preprocessingOnClickEvent)\n",
    "\n",
    "display(preprocessingButton)\n",
    "display(output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <img style=\"float: left\" src=\"./icons/learningModel.png\" width=\"25px\" height=\"25px\"/>&nbsp; Learning Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for learning model\n",
    "\n",
    "# When clicking EACH Classifier button\n",
    "def check_event(clickEvent):\n",
    "    tempButton = clickEvent\n",
    "    if (tempButton.icon == 'plus-square'):\n",
    "        if tempButton.description not in choosenClassifier:\n",
    "            choosenClassifier.append(tempButton.description)\n",
    "        tempButton.icon = 'minus-square'\n",
    "        tempButton.button_style='primary'\n",
    "    else:\n",
    "        tempButton.icon = 'plus-square'\n",
    "        for i in choosenClassifier:\n",
    "            if i == tempButton.description:\n",
    "                choosenClassifier.remove(i)\n",
    "                tempButton.button_style=''\n",
    "    checkForStepper()\n",
    "    checkIfOneSelected(listOfButtons)\n",
    "\n",
    "def checkForStepper():\n",
    "    if (MLkNNButton.button_style == '') & (BRMLkNNButton.button_style == ''):\n",
    "        k.disabled = True\n",
    "    else:\n",
    "        k.disabled = False\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# When selecting \"select all unselected\" and \"unselect all selected\" buttons\n",
    "def selectAllButtonOnClick(eventClick):\n",
    "    tempButton = eventClick\n",
    "    if tempButton.description=='Select All Unselected':\n",
    "        for button in listOfButtons:\n",
    "            if button.button_style == '':\n",
    "                button.click()\n",
    "    else:\n",
    "        for button in listOfButtons:\n",
    "            if button.button_style == 'primary':\n",
    "                button.click()\n",
    "    checkIfOneSelected(listOfButtons)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Activating \"Run Model\" button\n",
    "def checkIfOneSelected(listOfButtons):\n",
    "    nb = 0\n",
    "    for button in listOfButtons:\n",
    "        if button.button_style=='primary':\n",
    "            nb = nb + 1\n",
    "    if nb>=1:\n",
    "        runModelButton.disabled=False\n",
    "    else:\n",
    "        runModelButton.disabled=True\n",
    "        \n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Filling dropListClassifier drop down list according to choosen classifiers\n",
    "def fillDropListClassifier(dropList,choosenClassifier):\n",
    "    try:\n",
    "        dropList.options = {}\n",
    "    except:\n",
    "        dropList.options = {}\n",
    "    index = 0;\n",
    "    classifierDict = {}\n",
    "    for classifier in choosenClassifier:\n",
    "        classifierDict[str(classifier)] = index\n",
    "        index = index + 1\n",
    "    dropList.options = classifierDict\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------------LEARNING MODEL FUNCTIONS-------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# For determining quality for each classifier in order to give an advice\n",
    "def determineQuality(accuracyValue):\n",
    "    if accuracyValue < 0.5:\n",
    "        Quality.append('BAD')\n",
    "    elif 0.5 <= accuracyValue <= 0.7:\n",
    "        Quality.append('So-So')\n",
    "    elif 0.71 <= accuracyValue <= 0.88:\n",
    "        Quality.append('GOOD')\n",
    "    else:\n",
    "        Quality.append('VERY GOOD')\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# PT_build_Model for Problem Transformation methods\n",
    "def PT_build_Model(model,mlb_estimater,classifierName,algorithmName,Xtrain,ytrain,Xtest,ytest):\n",
    "    Methods.append('Problem Transformation')\n",
    "    clf = mlb_estimater(model,require_dense=[False,True])\n",
    "    clf.fit(Xtrain,ytrain)\n",
    "    # Prediction\n",
    "    clf_predictions = clf.predict(Xtest)\n",
    "    # Check the accuracy score and hamming loss\n",
    "    acc = accuracy_score(ytest,clf_predictions)\n",
    "    hmm = hamming_loss(ytest,clf_predictions)\n",
    "    ClassifierName.append(classifierName)\n",
    "    MethodsAlgorithms.append(algorithmName)\n",
    "    accuracyArray.append(acc)\n",
    "    hammingArray.append(hmm)\n",
    "    determineQuality(acc)\n",
    "    return clf\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# AA_build_Model for Alogrithm Adaptation methods\n",
    "def AA_build_Model(algorithm,kN,classifierName,algorithmName,X_train,y_train,X_test,y_test):\n",
    "    Methods.append('Algorithm Adaptation')\n",
    "    if algorithm==MLkNN:\n",
    "        classifier = algorithm(k=kN,s=0.5)\n",
    "    else:\n",
    "        classifier = algorithm(k=kN)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    acc = accuracy_score(y_test,y_pred)\n",
    "    hmm = hamming_loss(y_test,y_pred)\n",
    "    ClassifierName.append(classifierName)\n",
    "    MethodsAlgorithms.append(algorithmName)\n",
    "    accuracyArray.append(acc)\n",
    "    hammingArray.append(hmm)\n",
    "    determineQuality(acc)\n",
    "    return classifier \n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Reading training dataset -> Specific function\n",
    "def readTrainingDataset():\n",
    "    dataset = pd.read_json('./dataset/finalDataset1.json',orient='columns')\n",
    "    return dataset\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Mapping classifiers\n",
    "def MapClassifierToModelsWithFinalResult(choosenClassifier,numberOfKNN,X_train, X_test, y_train, y_test):\n",
    "    listOfRunningClassifiers = []\n",
    "    \n",
    "    # For giving final result\n",
    "    global Methods \n",
    "    Methods = []\n",
    "    global ClassifierName \n",
    "    ClassifierName = []\n",
    "    global MethodsAlgorithms\n",
    "    MethodsAlgorithms = []\n",
    "    global accuracyArray\n",
    "    accuracyArray = []\n",
    "    global hammingArray\n",
    "    hammingArray = []\n",
    "    global Quality\n",
    "    Quality = []\n",
    "    \n",
    "    for classifier in choosenClassifier:\n",
    "        if classifier == 'Binary Relevance with NomialNB':\n",
    "            # BinaryRelevance\n",
    "            BR1 = PT_build_Model(MultinomialNB(),BinaryRelevance,'BinaryRelevance','MultinominalNB',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(BR1)\n",
    "        elif classifier == 'Binary Relevance with RandomForestClassifier':\n",
    "            # BinaryRelevance\n",
    "            BR2 = PT_build_Model(RandomForestClassifier(),BinaryRelevance,'BinaryRelevance','RandomForestClassifier',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(BR2)\n",
    "        elif classifier == 'ClassifierChain with NomialNB':\n",
    "            # ClassifierChain\n",
    "            CC1 = PT_build_Model(MultinomialNB(),ClassifierChain,'ClassifierChain','MultinominalNB',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(CC1)\n",
    "        elif classifier == 'Classifier Chain with RandomForestClassifier':\n",
    "            # ClassifierChain\n",
    "            CC2 = PT_build_Model(RandomForestClassifier(),ClassifierChain,'ClassifierChain','RandomForestClassifier',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(CC2)\n",
    "        elif classifier == 'LabelPowerset with NomialNB':\n",
    "            # LabelPowerset\n",
    "            LP1 = PT_build_Model(MultinomialNB(),LabelPowerset,'LabelPowerset','MultinominalNB',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(LP1)\n",
    "        elif classifier == 'LabelPowerset with RandomForestClassifier':\n",
    "            # LabelPowerset\n",
    "            LP2 = PT_build_Model(RandomForestClassifier(),LabelPowerset,'LabelPowerset','RandomForestClassifier',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(LP2)\n",
    "        elif classifier == 'MLkNN':\n",
    "            # ML-KNN\n",
    "            MK1 = AA_build_Model(MLkNN,numberOfKNN,'MLkNN','MLkNN',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(MK1)\n",
    "        elif classifier == 'BRMLkNN':\n",
    "            # ML-KNN\n",
    "            MK2 = AA_build_Model(BRkNNaClassifier,numberOfKNN,'BRkNNaClassifier','BRkNNaClassifier',X_train,y_train,X_test,y_test)\n",
    "            listOfRunningClassifiers.append(MK2)\n",
    "\n",
    "    # Making Final DataFrame\n",
    "    dataDict = {'Method': Methods,\n",
    "                'Classifier':ClassifierName,\n",
    "                'Algorithm': MethodsAlgorithms,\n",
    "                'Accuracy': accuracyArray,\n",
    "                'Hamming Loss': hammingArray,\n",
    "                'Quality': Quality}\n",
    "    # Making a dataframe\n",
    "    resultDf = pd.DataFrame(dataDict)\n",
    "    \n",
    "    # Returning final result and list of running classifiers\n",
    "    return listOfRunningClassifiers, resultDf\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "def appendTextToConsole(textAreaPane,Text):\n",
    "    textAreaPane.value = textAreaPane.value + \"\\r\" + Text\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------\n",
    "# Train model\n",
    "def runModelClickEvent(event):\n",
    "    runModelButton.icon = \"spinner\"\n",
    "    output3.clear_output()\n",
    "    fillDropListClassifier(dropListClassifier,choosenClassifier)\n",
    "    # For console\n",
    "    out13 = widgets.Output()\n",
    "    trainingResult = Accordion(children=[out13], selected_index=0)\n",
    "    trainingConsoleText = Textarea(value=\"Training Console:\", rows=10, disabled=True, layout=Layout(width=\"auto\"))\n",
    "    trainingResult.set_title(0,\"Training Console:\")\n",
    "    \n",
    "    with output3:\n",
    "        display(trainingResult)\n",
    "        with out13:\n",
    "            display(trainingConsoleText)\n",
    "    \n",
    "    # Reading training dataset\n",
    "    trainingDataset = readTrainingDataset()\n",
    "    datasetRows = trainingDataset.shape[0]\n",
    "    datasetColumns = trainingDataset.shape[1]\n",
    "    appendTextToConsole(trainingConsoleText,\"▶ Reading training dataset with size: \"+str(datasetRows)+\" rows * \"+str(datasetColumns)+\" columns\")\n",
    "    \n",
    "    # Spliting training dataset\n",
    "    X = trainingDataset[[\"NumberOfAccomplishedTasks\", \"OrganizationManagementProportion\", \"TrainingLearningProportion\", \"CoorporationProportion\", \"VarietyWorkProportion\", \"StartWorkingMorning\", \"WorkingLongTime\", \"taskLocation\"]].values\n",
    "    y = trainingDataset[[\"SelfManagement\",\"WillingnessToLearn\",\"Energy\",\"Persistence\",\"Mobility\"]].values\n",
    "    \n",
    "    appendTextToConsole(trainingConsoleText,\"▶ Droping personID column..\")\n",
    "    \n",
    "    appendTextToConsole(trainingConsoleText,\"▶ Spliting dataset into training set (80%) and test set (20%):\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    trainingsetRows = X_train.shape[0]\n",
    "    trainingsetColumns = X_train.shape[1]\n",
    "    testsetRows = X_test.shape[0]\n",
    "    testsetColumns = X_test.shape[1]\n",
    "    appendTextToConsole(trainingConsoleText,\"  ▶▶ Training set size: \"+str(trainingsetRows)+\" rows * \"+str(trainingsetColumns)+\" columns\")\n",
    "    appendTextToConsole(trainingConsoleText,\"  ▶▶ Test set size: \"+str(testsetRows)+\" rows * \"+str(testsetColumns)+\" columns\")\n",
    "    \n",
    "    global listOfTrainedRunningClassifiers\n",
    "    \n",
    "    numberOfKNN = k.value\n",
    "    listOfTrainedRunningClassifiers, adviceResult = MapClassifierToModelsWithFinalResult(choosenClassifier,numberOfKNN,X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    for item in choosenClassifier:\n",
    "        appendTextToConsole(trainingConsoleText,\"▶ Training model with \"+str(item))\n",
    "    \n",
    "    \n",
    "    adviceResultVeryGood = adviceResult[adviceResult.Quality=='VERY GOOD'].reset_index(drop=True)\n",
    "    adviceResultGood = adviceResult[adviceResult.Quality=='GOOD'].reset_index(drop=True)\n",
    "    adviceResultSoSo = adviceResult[adviceResult.Quality=='So-So'].reset_index(drop=True)\n",
    "    adviceResultBAD = adviceResult[adviceResult.Quality=='BAD'].reset_index(drop=True)\n",
    "    listOfPrettyGoodResult = []\n",
    "    for vgr in range(len(adviceResultVeryGood)):\n",
    "        text = str(adviceResultVeryGood.Classifier[vgr]) + ' with ' + str(adviceResultVeryGood.Algorithm[vgr])\n",
    "        listOfPrettyGoodResult.append(Button(description=text,layout=Layout(width=\"auto\"),disabled=True,icon='star', button_style='success'))\n",
    "    for gr in range(len(adviceResultGood)):\n",
    "        text = str(adviceResultGood.Classifier[gr]) + ' with ' + str(adviceResultGood.Algorithm[gr])\n",
    "        listOfPrettyGoodResult.append(Button(description=text,layout=Layout(width=\"auto\"),disabled=True,icon='star-half-o', button_style='primary'))\n",
    "    for ssr in range(len(adviceResultSoSo)):\n",
    "        text = str(adviceResultSoSo.Classifier[ssr]) + ' with ' + str(adviceResultSoSo.Algorithm[ssr])\n",
    "        listOfPrettyGoodResult.append(Button(description=text,layout=Layout(width=\"auto\"),disabled=True,icon='star-o', button_style='warning'))\n",
    "    for br in range(len(adviceResultBAD)):\n",
    "        text = str(adviceResultBAD.Classifier[br]) + ' with ' + str(adviceResultBAD.Algorithm[br])\n",
    "        listOfPrettyGoodResult.append(Button(description=text,layout=Layout(width=\"auto\"),disabled=True,icon='close', button_style='danger'))\n",
    "        \n",
    "    out14 = widgets.Output()\n",
    "    out15 = widgets.Output()\n",
    "    trainingResult.children = [out13,out14,out15]\n",
    "    trainingResult.set_title(1,\"Result:\")\n",
    "    trainingResult.set_title(2,\"Advice which classifier you should use:\")\n",
    "    \n",
    "    if len(listOfTrainedRunningClassifiers)!=0:\n",
    "        predictionButton.disabled=False\n",
    "    else:\n",
    "        predictionButton.disabled=True\n",
    "    \n",
    "    activatePredictionButton()\n",
    "    \n",
    "    with out14:\n",
    "        display(adviceResult)\n",
    "    with out15:\n",
    "        display(HBox(listOfPrettyGoodResult,layout=Layout(width='100%',display='inline-flex',flex_flow='row wrap')))\n",
    "    \n",
    "    runModelButton.icon = \"gear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c978db3d1abf4c0e9a3e6189eaf11948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='▶ Choose Classifiers you want to train model on : ', layout=Layout(width='auto')),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ff796efea34154ad6cc94d1eb876e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='Binary Relevance with NomialNB', icon='plus-square', layout=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4364164886484b978463ff2d23b46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='▶ Now run learning model : ', layout=Layout(width='auto')), Button(description='Ru…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45e756eeb5f45648ad30cfb5fe5f872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning:\n",
      "\n",
      "Pass n_neighbors=3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning:\n",
      "\n",
      "Pass n_neighbors=3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output3 = widgets.Output()\n",
    "\n",
    "layout = Layout(display='flex',\n",
    "                align_items='center',\n",
    "                width='50%')\n",
    "\n",
    "runModelButton = Button(description=\"Run Model\", tooltip=\"Learn Model on different Algorithms to give you an advice\",\n",
    "                       layout = Layout(width=\"auto\"), icon=\"gear\", disabled=True)\n",
    "runModelButton.on_click(runModelClickEvent)\n",
    "\n",
    "myModelAlgorithms = Label(value='▶ Choose Classifiers you want to train model on : ', layout= Layout(width=\"auto\"))\n",
    "mymodelLabel = Label(value='▶ Now run learning model : ', layout= Layout(width=\"auto\"))\n",
    "\n",
    "BRNBButton = Button(description=\"Binary Relevance with NomialNB\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "BRRFButton = Button(description=\"Binary Relevance with RandomForestClassifier\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "\n",
    "CCNBButton = Button(description=\"ClassifierChain with NomialNB\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "CCRFButton = Button(description=\"Classifier Chain with RandomForestClassifier\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "\n",
    "LPNBButton = Button(description=\"LabelPowerset with NomialNB\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "LPRFButton = Button(description=\"LabelPowerset with RandomForestClassifier\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "\n",
    "MLkNNButton = Button(description=\"MLkNN\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "BRMLkNNButton = Button(description=\"BRMLkNN\", disabled=False, layout = layout, icon=\"plus-square\")\n",
    "\n",
    "k = IntSlider(description= \"k =\", min=2, max=10, step=1, readout=True, value=3, disabled = True)\n",
    "\n",
    "listOfButtons = [BRNBButton, BRRFButton, CCNBButton, CCRFButton, LPNBButton, LPRFButton, MLkNNButton, BRMLkNNButton]\n",
    "\n",
    "global choosenClassifier\n",
    "choosenClassifier = []\n",
    "\n",
    "global allSelected\n",
    "\n",
    "BRNBButton.on_click(check_event)\n",
    "BRRFButton.on_click(check_event)\n",
    "CCNBButton.on_click(check_event)\n",
    "CCRFButton.on_click(check_event)\n",
    "LPNBButton.on_click(check_event)\n",
    "LPRFButton.on_click(check_event)\n",
    "MLkNNButton.on_click(check_event)\n",
    "BRMLkNNButton.on_click(check_event)\n",
    "\n",
    "BR = HBox([BRNBButton, BRRFButton])\n",
    "CC = HBox([CCNBButton, CCRFButton])\n",
    "LP = HBox([LPNBButton, LPRFButton])\n",
    "KN = HBox([MLkNNButton, BRMLkNNButton])\n",
    "\n",
    "selectAllButton = Button(description=\"Select All Unselected\", layout=Layout(width=\"auto\"), icon='check-square')\n",
    "selectAllButton.on_click(selectAllButtonOnClick)\n",
    "UnselectAllButton = Button(description=\"UnSelect All Selected\", layout=Layout(width=\"auto\"), icon='square-o')\n",
    "UnselectAllButton.on_click(selectAllButtonOnClick)\n",
    "\n",
    "\n",
    "display(HBox([myModelAlgorithms,selectAllButton,UnselectAllButton,k]))\n",
    "display(VBox([BR,CC,LP,KN]))\n",
    "display(HBox([mymodelLabel,runModelButton]))\n",
    "\n",
    "display(output3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <img style=\"float: left\" src=\"./icons/prediction.png\" width=\"35px\" height=\"35px\"/>&nbsp; Predict volunteer competency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for prediction\n",
    "\n",
    "# Getting the selected value from dropListClassifier\n",
    "def changeEvent(change):\n",
    "    global selection\n",
    "    allOptions = dropListClassifier.options\n",
    "    allKeys = list(allOptions.keys())\n",
    "    allValues = list(allOptions.values())\n",
    "    for i in allValues:\n",
    "        if dropListClassifier.value == i:\n",
    "            selection = i\n",
    "    return selection\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "# Prediction Button Click\n",
    "def predictionClickEvent(event):\n",
    "    # clearing output4\n",
    "    output4.clear_output()\n",
    "    \n",
    "    # Get pre-processed dataset\n",
    "    generatedDataset = getFinalPreprocessedDataset()\n",
    "    \n",
    "    # taking the same columns of training dataset\n",
    "    columnsWithoutOutput = generatedDataset[[\"NumberOfAccomplishedTasks\", \"OrganizationManagementProportion\", \"TrainingLearningProportion\", \"CoorporationProportion\", \"VarietyWorkProportion\", \"StartWorkingMorning\", \"WorkingLongTime\", \"taskLocation\"]].values\n",
    "    predictionResult = np.array(columnsWithoutOutput).reshape((1, -1))\n",
    "    \n",
    "    # Prediction process using the choosed classifier\n",
    "    predictionClassifier = listOfTrainedRunningClassifiers[selection]\n",
    "    predictionClassifier = predictionClassifier.predict(predictionResult).toarray()\n",
    "    \n",
    "    # Making result in a pretty output    \n",
    "    for item in predictionClassifier:\n",
    "        finalPredictionResult = item\n",
    "    \n",
    "    volumnteerName = generatedDataset.personName[0]\n",
    "    \n",
    "    predictionLabel = Label(value=\"Prediction \"+str(volumnteerName)+\"'s competencies using \"+str(listOfTrainedRunningClassifiers[selection]),\n",
    "                           layout = Layout(width='auto'))\n",
    "    \n",
    "    listOfPredictedResult = [];\n",
    "    for counter in range(len(finalPredictionResult)):\n",
    "        if counter==0: # Self Management Competency\n",
    "            if finalPredictionResult[counter] == 0:\n",
    "                listOfPredictedResult.append(Button(description=\"Self Management\",layout=Layout(width=\"auto\"),disabled=True,icon='close', button_style='danger'))\n",
    "            else:\n",
    "                listOfPredictedResult.append(Button(description=\"Self Management\",layout=Layout(width=\"auto\"),disabled=True,icon='check', button_style='success'))\n",
    "        elif counter==1: # Willingness To Learn Competency\n",
    "            if finalPredictionResult[counter] == 0:\n",
    "                listOfPredictedResult.append(Button(description=\"Willingness To Learn\",layout=Layout(width=\"auto\"),disabled=True,icon='close', button_style='danger'))\n",
    "            else:\n",
    "                listOfPredictedResult.append(Button(description=\"Willingness To Learn\",layout=Layout(width=\"auto\"),disabled=True,icon='check', button_style='success'))\n",
    "        elif counter==2: # Energy Competency\n",
    "            if finalPredictionResult[counter] == 0:\n",
    "                listOfPredictedResult.append(Button(description=\"Energy\",layout=Layout(width=\"auto\"),disabled=True,icon='close', button_style='danger'))\n",
    "            else:\n",
    "                listOfPredictedResult.append(Button(description=\"Energy\",layout=Layout(width=\"auto\"),disabled=True,icon='check', button_style='success'))\n",
    "        elif counter==3: # Persistence Competency\n",
    "            if finalPredictionResult[counter] == 0:\n",
    "                listOfPredictedResult.append(Button(description=\"Persistence\",layout=Layout(width=\"auto\"),disabled=True,icon='close', button_style='danger'))\n",
    "            else:\n",
    "                listOfPredictedResult.append(Button(description=\"Persistence\",layout=Layout(width=\"auto\"),disabled=True,icon='check', button_style='success'))\n",
    "        elif counter==4: # Mobility Competency\n",
    "            if finalPredictionResult[counter] == 0:\n",
    "                listOfPredictedResult.append(Button(description=\"Mobility\",layout=Layout(width=\"auto\"),disabled=True,icon='close', button_style='danger'))\n",
    "            else:\n",
    "                listOfPredictedResult.append(Button(description=\"Mobility\",layout=Layout(width=\"auto\"),disabled=True,icon='check', button_style='success'))\n",
    "    \n",
    "    out16 = widgets.Output();\n",
    "    out17 = widgets.Output();\n",
    "    with output4:\n",
    "        display(VBox([out16,out17]))\n",
    "        with out16:\n",
    "            display(predictionLabel)\n",
    "        with out17:\n",
    "            display(HBox(listOfPredictedResult,layout=Layout(width='100%',display='inline-flex',flex_flow='row wrap')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'widgets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77fbdb79a3c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlayout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m dropListClassifier = Dropdown(\n\u001b[0;32m      5\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'widgets' is not defined"
     ]
    }
   ],
   "source": [
    "output4 = widgets.Output()\n",
    "layout = Layout(width=\"auto\")\n",
    "\n",
    "dropListClassifier = Dropdown(\n",
    "            options={'':0},\n",
    "            value=0,\n",
    "            description='Choose Algorithm/Estimator:',\n",
    "            layout = layout,\n",
    "            style= {'description_width':'auto', 'description_color':'red'}\n",
    "            )\n",
    "dropListClassifier.observe(changeEvent, names=['value'])\n",
    "\n",
    "predictionButton = Button(description=\"Predict volunteer competencies\", layout =Layout(width=\"auto\"), icon='question-circle', disabled=True)\n",
    "predictionButton.on_click(predictionClickEvent)\n",
    "\n",
    "items = HBox([dropListClassifier])\n",
    "\n",
    "display(items)\n",
    "\n",
    "display(predictionButton)\n",
    "display(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
